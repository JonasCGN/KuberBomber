# ğŸ¯ Sistema de SimulaÃ§Ã£o de Confiabilidade - Kubernetes Chaos Engineering

## ğŸ“– VisÃ£o Geral

Este sistema implementa simulaÃ§Ã£o de confiabilidade acadÃªmica para clusters Kubernetes, permitindo anÃ¡lise de mÃ©tricas crÃ­ticas como **MTTF** (Mean Time To Failure), **MTBF** (Mean Time Between Failures) e **MTTR** (Mean Time To Recovery).

### ğŸš€ Como Usar

```bash
# Comando principal
python3 main.py reliability start [OPÃ‡Ã•ES]

# Exemplo bÃ¡sico
python3 main.py reliability start --duration 1.0 --acceleration 10000

# Exemplo avanÃ§ado
python3 main.py reliability start \
    --duration 2.0 \
    --acceleration 50000 \
    --csv-path "teste_completo.csv" \
    --namespace "production"
```

## ğŸ”§ ParÃ¢metros de ConfiguraÃ§Ã£o

| ParÃ¢metro | PadrÃ£o | DescriÃ§Ã£o |
|-----------|--------|-----------|
| `--duration` | 1.0 | DuraÃ§Ã£o da simulaÃ§Ã£o em **horas reais** |
| `--acceleration` | 10000.0 | Fator de aceleraÃ§Ã£o temporal (1h real = X horas simuladas) |
| `--csv-path` | `reliability_simulation.csv` | Arquivo CSV de saÃ­da com logs detalhados |
| `--namespace` | `default` | Namespace Kubernetes para testes |

### ğŸ“Š AceleraÃ§Ã£o Temporal

O sistema usa **aceleraÃ§Ã£o temporal** para simular longos perÃ­odos em tempo reduzido:

- **AceleraÃ§Ã£o 10.000x**: 1 hora real = 10.000 horas simuladas (~1,14 anos)
- **AceleraÃ§Ã£o 50.000x**: 1 hora real = 50.000 horas simuladas (~5,7 anos)
- **AceleraÃ§Ã£o 100.000x**: 1 hora real = 100.000 horas simuladas (~11,4 anos)

## ğŸ’¥ Tipos de Falha Implementados

### 1. ğŸ”¸ POD_KILL (`pod_kill`)
**DescriÃ§Ã£o**: Mata o processo principal (PID 1) dentro do container do pod.

**Comando Executado**:
```bash
kubectl exec <pod> -n <namespace> -- kill -9 1
```

**Impacto**:
- âœ… Mata apenas a aplicaÃ§Ã£o
- âœ… Container pode reiniciar automaticamente
- âœ… Pod permanece "vivo" no Kubernetes
- âœ… Simula crash da aplicaÃ§Ã£o

**Tempo de RecuperaÃ§Ã£o**: 5-30 segundos (restart automÃ¡tico)

---

### 2. ğŸ”„ POD_REBOOT (`pod_reboot`)
**DescriÃ§Ã£o**: ForÃ§a delete completo do pod, simulando reboot total.

**Comando Executado**:
```bash
kubectl delete pod <pod> -n <namespace> --force --grace-period=0
```

**Impacto**:
- ğŸ”¥ Deleta pod completamente
- ğŸ”„ Kubernetes recria automaticamente (se gerenciado por Deployment)
- ğŸ”„ Novo IP, novo hostname
- ğŸ”„ Simula reboot completo da mÃ¡quina virtual

**Tempo de RecuperaÃ§Ã£o**: 30-120 segundos (criaÃ§Ã£o de novo pod)

---

### 3. ğŸ–¥ï¸ NODE_REBOOT (`node_reboot`)
**DescriÃ§Ã£o**: Reinicia o nÃ³ worker completamente via reboot do sistema.

**Comando Executado**:
```bash
# Via node_injector usando SSH ou kubectl debug
sudo reboot
```

**Impacto**:
- ğŸ’¥ Reinicia mÃ¡quina fÃ­sica/virtual
- ğŸ’¥ Todos os pods do nÃ³ sÃ£o perdidos
- ğŸ’¥ Kubernetes precisa reagendar pods
- ğŸ’¥ Simula falha de hardware/sistema

**Tempo de RecuperaÃ§Ã£o**: 2-10 minutos (boot + reagendamento)

---

### 4. âš¡ NODE_KILL_ALL (`node_kill_all`)
**DescriÃ§Ã£o**: Mata processos nÃ£o-crÃ­ticos do nÃ³, preservando sistema base.

**Comandos Executados**:
```bash
kubectl debug node/<node> -it --image=busybox -- \
    chroot /host bash -c \
    "pkill -f -9 '(?!systemd|kubelet|dockerd|containerd).*'"
```

**Impacto**:
- âš¡ Mata aplicaÃ§Ãµes e containers
- âš¡ Preserva kubelet, systemd, docker
- âš¡ NÃ³ permanece "responsivo"
- âš¡ Simula sobrecarga de processos

**Tempo de RecuperaÃ§Ã£o**: 1-5 minutos (restart de containers)

---

### 5. â˜ ï¸ NODE_KILL_CRITICAL (`node_kill_critical`)
**DescriÃ§Ã£o**: **MUITO DESTRUTIVO** - Mata processos crÃ­ticos do Kubernetes.

**Processos Alvos**:
- `kubelet` - Agente Kubernetes no nÃ³
- `containerd` - Runtime de containers  
- `dockerd` - Docker daemon
- `kube-proxy` - Proxy de rede
- `calico-node` - CNI (networking)
- `flannel` - CNI alternativo
- `coredns` - DNS interno
- `etcd` - Base de dados (se no worker)

**Comandos Executados**:
```bash
# Para cada processo crÃ­tico
kubectl debug node/<node> -it --image=busybox -- \
    chroot /host bash -c \
    "pkill -f -9 '<processo>'"

# Ataque final
kubectl debug node/<node> -it --image=busybox -- \
    chroot /host bash -c \
    "pkill -f -9 'containerd|docker|runc|kubelet|kube-proxy'"
```

**Impacto**:
- â˜ ï¸ **PODE QUEBRAR O NÃ“ PERMANENTEMENTE**
- â˜ ï¸ Perde comunicaÃ§Ã£o com cluster
- â˜ ï¸ Pode exigir reboot manual
- â˜ ï¸ Simula falhas catastrÃ³ficas

**Tempo de RecuperaÃ§Ã£o**: 10+ minutos (ou manual)

## ğŸ“ˆ MÃ©tricas Calculadas

### ğŸ¯ MÃ©tricas Principais

| MÃ©trica | DescriÃ§Ã£o | Unidade |
|---------|-----------|---------|
| **MTTF** | Mean Time To Failure - Tempo mÃ©dio atÃ© falha | Horas |
| **MTBF** | Mean Time Between Failures - Tempo mÃ©dio entre falhas | Horas |
| **MTTR** | Mean Time To Recovery - Tempo mÃ©dio de recuperaÃ§Ã£o | Segundos |
| **Availability** | Disponibilidade do sistema | Percentual |
| **Reliability** | Confiabilidade em 1000h | Percentual |
| **Failure Rate** | Taxa de falha | Falhas/hora |

### ğŸ“Š DistribuiÃ§Ãµes EstatÃ­sticas

O sistema suporta diferentes distribuiÃ§Ãµes para intervalos de falha:

1. **Exponencial** (padrÃ£o): Falhas aleatÃ³rias uniformes
2. **Weibull**: Modelagem de desgaste/envelhecimento
3. **Normal**: Falhas previsÃ­veis com variaÃ§Ã£o

## ğŸ“‹ Fluxo de ExecuÃ§Ã£o Detalhado

### 1. ğŸ¬ InicializaÃ§Ã£o
```
[InÃ­cio] â†’ Carrega configuraÃ§Ãµes â†’ Conecta Kubernetes â†’ Inicializa CSV
```

### 2. ğŸ¯ SeleÃ§Ã£o de Alvo
```
[Scheduler] â†’ Escolhe modo de falha aleatÃ³rio â†’ Seleciona alvo vÃ¡lido
```

### 3. ğŸ’¥ InjeÃ§Ã£o de Falha
```
[Falha] â†’ Mede saÃºde antes â†’ Executa comando â†’ Log evento â†’ Inicia timer
```

### 4. ğŸ” Monitoramento
```
[Monitor] â†’ Detecta recuperaÃ§Ã£o â†’ Calcula MTTR â†’ Atualiza mÃ©tricas â†’ Log recuperaÃ§Ã£o
```

### 5. ğŸ“Š CÃ¡lculo de MÃ©tricas
```
[MÃ©tricas] â†’ MTTF/MTBF/MTTR â†’ Availability â†’ Reliability â†’ Salva CSV
```

### 6. ğŸ”„ Loop ContÃ­nuo
```
[Loop] â†’ Calcula prÃ³xima falha â†’ Aguarda â†’ Volta ao passo 2
```

## ğŸ“ Arquivo CSV de SaÃ­da

O sistema gera um CSV detalhado com todas as informaÃ§Ãµes:

```csv
timestamp,simulation_time_hours,real_time_seconds,event_type,failure_mode,target,target_type,failure_id,start_time,end_time,duration_seconds,duration_hours,mttf_hours,mtbf_hours,mttr_seconds,mttr_hours,next_failure_in_hours,cluster_health_before,cluster_health_after,additional_info
```

### ğŸ“‹ Tipos de Eventos Logados

- `failure_initiated` - Falha iniciada
- `failure_detected` - Falha confirmada
- `recovery_started` - RecuperaÃ§Ã£o iniciada
- `recovery_completed` - RecuperaÃ§Ã£o concluÃ­da
- `simulation_started` - SimulaÃ§Ã£o iniciada
- `simulation_stopped` - SimulaÃ§Ã£o parada

## ğŸ® Exemplos de Uso PrÃ¡tico

### ğŸ“Š AnÃ¡lise de Disponibilidade
```bash
# Simula 6 meses de operaÃ§Ã£o em 30 minutos
python3 main.py reliability start \
    --duration 0.5 \
    --acceleration 8760 \
    --csv-path "analise_6meses.csv"
```

### ğŸ”¬ Teste de Stress Intenso
```bash
# Acelera muito para muitas falhas
python3 main.py reliability start \
    --duration 2.0 \
    --acceleration 100000 \
    --csv-path "stress_test.csv"
```

### ğŸ­ SimulaÃ§Ã£o ProduÃ§Ã£o
```bash
# Teste no namespace de produÃ§Ã£o
python3 main.py reliability start \
    --duration 1.0 \
    --acceleration 10000 \
    --csv-path "prod_reliability.csv" \
    --namespace "production"
```

## ğŸ“Š AnÃ¡lise dos Resultados

### ğŸ“ˆ InterpretaÃ§Ã£o das MÃ©tricas

1. **MTTF Alto**: Sistema estÃ¡vel, falhas raras
2. **MTTR Baixo**: RecuperaÃ§Ã£o rÃ¡pida, boa resiliÃªncia
3. **Availability > 99%**: Sistema altamente disponÃ­vel
4. **Reliability > 90%**: ConfiÃ¡vel para 1000h operaÃ§Ã£o

### ğŸ¯ Benchmarks TÃ­picos

| Tipo de Sistema | MTTF (horas) | MTTR (segundos) | Availability |
|-----------------|--------------|-----------------|--------------|
| **CrÃ­tico** | 8760+ | <60 | >99.9% |
| **ProduÃ§Ã£o** | 720+ | <300 | >99% |
| **Desenvolvimento** | 168+ | <600 | >95% |

## âš ï¸ Avisos Importantes

### ğŸš¨ Modo NODE_KILL_CRITICAL
- **MUITO PERIGOSO** - pode quebrar nÃ³s permanentemente
- Use apenas em ambientes de teste
- Tenha plano de recuperaÃ§Ã£o manual

### ğŸ”’ Requisitos de SeguranÃ§a
- PermissÃµes administrativas no cluster
- Acesso via kubectl configurado
- Pods com privilÃ©gios para debug nodes

### ğŸ“‹ PrÃ©-requisitos
- Cluster Kubernetes funcional
- kubectl configurado
- Python 3.8+
- DependÃªncias: kubernetes, numpy, rich, click

## ğŸ¯ ConclusÃ£o

Este sistema oferece anÃ¡lise acadÃªmica robusta de confiabilidade para clusters Kubernetes, permitindo:

- âœ… Testes controlados de resiliÃªncia
- âœ… AnÃ¡lise quantitativa de disponibilidade  
- âœ… MÃ©tricas acadÃªmicas padrÃ£o (MTTF/MTBF/MTTR)
- âœ… SimulaÃ§Ã£o acelerada de longos perÃ­odos
- âœ… Logging detalhado para anÃ¡lise posterior

**Use com responsabilidade e sempre em ambientes de teste!** ğŸ›¡ï¸