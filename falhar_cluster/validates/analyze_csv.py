#!/usr/bin/env python3
"""
üìä An√°lise Detalhada do CSV de Simula√ß√£o de Confiabilidade
"""

import pandas as pd
import numpy as np
from datetime import datetime
import json

def analyze_reliability_csv(csv_path):
    """An√°lise detalhada do CSV de simula√ß√£o de confiabilidade"""
    
    print("üìä Analisando dados de simula√ß√£o de confiabilidade...")
    
    # Carregar dados
    df = pd.read_csv(csv_path)
    print(f"‚úÖ Dados carregados: {len(df)} eventos")
    
    # Separar tipos de eventos
    failures = df[df['event_type'] == 'failure_initiated'].copy()
    recoveries = df[df['event_type'] == 'recovery_completed'].copy()
    
    print(f"\nüìà Resumo dos Eventos:")
    print(f"  ‚Ä¢ Falhas iniciadas: {len(failures)}")
    print(f"  ‚Ä¢ Recupera√ß√µes completadas: {len(recoveries)}")
    print(f"  ‚Ä¢ Taxa de recupera√ß√£o: {len(recoveries)/len(failures)*100:.1f}%")
    
    # An√°lise de falhas por tipo
    print(f"\nüí• An√°lise de Falhas:")
    failure_breakdown = failures['failure_mode'].value_counts()
    for failure_type, count in failure_breakdown.items():
        percentage = count / len(failures) * 100
        print(f"  ‚Ä¢ {failure_type}: {count} ({percentage:.1f}%)")
    
    # An√°lise de alvos
    print(f"\nüéØ An√°lise de Alvos:")
    target_breakdown = failures['target_type'].value_counts()
    for target_type, count in target_breakdown.items():
        print(f"  ‚Ä¢ {target_type}: {count}")
    
    # Principais alvos afetados
    top_targets = failures['target'].value_counts().head(5)
    print(f"\nüî• Alvos Mais Afetados:")
    for target, count in top_targets.items():
        print(f"  ‚Ä¢ {target}: {count} falhas")
    
    # An√°lise de tempo de recupera√ß√£o
    if len(recoveries) > 0 and 'duration_seconds' in recoveries.columns:
        recovery_times = recoveries['duration_seconds'].dropna()
        
        print(f"\n‚è±Ô∏è Tempos de Recupera√ß√£o:")
        print(f"  ‚Ä¢ M√©dia: {recovery_times.mean():.2f}s")
        print(f"  ‚Ä¢ Mediana: {recovery_times.median():.2f}s")
        print(f"  ‚Ä¢ Desvio padr√£o: {recovery_times.std():.2f}s")
        print(f"  ‚Ä¢ M√≠nimo: {recovery_times.min():.2f}s")
        print(f"  ‚Ä¢ M√°ximo: {recovery_times.max():.2f}s")
        
        # Percentis
        p25 = recovery_times.quantile(0.25)
        p75 = recovery_times.quantile(0.75)
        p95 = recovery_times.quantile(0.95)
        
        print(f"  ‚Ä¢ P25: {p25:.2f}s")
        print(f"  ‚Ä¢ P75: {p75:.2f}s") 
        print(f"  ‚Ä¢ P95: {p95:.2f}s")
        
        # Detectar outliers
        iqr = p75 - p25
        lower_bound = p25 - 1.5 * iqr
        upper_bound = p75 + 1.5 * iqr
        outliers = recovery_times[(recovery_times < lower_bound) | (recovery_times > upper_bound)]
        
        if len(outliers) > 0:
            print(f"  ‚ö†Ô∏è Outliers detectados: {len(outliers)} ({len(outliers)/len(recovery_times)*100:.1f}%)")
        else:
            print(f"  ‚úÖ Nenhum outlier detectado")
    
    # M√©tricas finais de confiabilidade
    last_row = df.iloc[-1]
    print(f"\nüìä M√©tricas Finais de Confiabilidade:")
    
    if 'mttf_hours' in last_row and pd.notna(last_row['mttf_hours']):
        mttf = last_row['mttf_hours']
        print(f"  ‚Ä¢ MTTF: {mttf:.2f} horas ({mttf*60:.0f} minutos)")
    
    if 'mtbf_hours' in last_row and pd.notna(last_row['mtbf_hours']):
        mtbf = last_row['mtbf_hours']
        print(f"  ‚Ä¢ MTBF: {mtbf:.2f} horas ({mtbf*60:.0f} minutos)")
    
    if 'mttr_seconds' in last_row and pd.notna(last_row['mttr_seconds']):
        mttr = last_row['mttr_seconds']
        print(f"  ‚Ä¢ MTTR: {mttr:.2f} segundos")
    
    # An√°lise temporal da simula√ß√£o
    if 'simulation_time_hours' in df.columns and 'real_time_seconds' in df.columns:
        sim_hours = df['simulation_time_hours'].max()
        real_seconds = df['real_time_seconds'].max()
        real_minutes = real_seconds / 60
        acceleration = sim_hours / (real_seconds / 3600) if real_seconds > 0 else 0
        
        print(f"\n‚ö° M√©tricas de Simula√ß√£o:")
        print(f"  ‚Ä¢ Tempo simulado: {sim_hours:.2f} horas")
        print(f"  ‚Ä¢ Tempo real: {real_minutes:.2f} minutos ({real_seconds:.1f}s)")
        print(f"  ‚Ä¢ Fator de acelera√ß√£o: {acceleration:.0f}x")
        print(f"  ‚Ä¢ Taxa de eventos: {len(df)/real_minutes:.1f} eventos/min")
    
    # Timeline de falhas por hora simulada
    if len(failures) > 0:
        print(f"\nüìà Distribui√ß√£o Temporal de Falhas:")
        failures_timeline = failures.copy()
        failures_timeline['sim_hour_bin'] = (failures_timeline['simulation_time_hours'] // 50) * 50
        hourly_failures = failures_timeline['sim_hour_bin'].value_counts().sort_index()
        
        for hour_bin, count in hourly_failures.head(10).items():
            print(f"  ‚Ä¢ Horas {hour_bin:.0f}-{hour_bin+50:.0f}: {count} falhas")
    
    # An√°lise de efici√™ncia de recupera√ß√£o por tipo
    print(f"\nüîÑ Efici√™ncia de Recupera√ß√£o por Tipo:")
    for failure_type in failures['failure_mode'].unique():
        if pd.notna(failure_type):
            type_failures = len(failures[failures['failure_mode'] == failure_type])
            type_recoveries = len(recoveries[recoveries['failure_mode'] == failure_type])
            efficiency = type_recoveries / type_failures * 100 if type_failures > 0 else 0
            print(f"  ‚Ä¢ {failure_type}: {efficiency:.1f}% ({type_recoveries}/{type_failures})")
    
    # Valida√ß√£o da qualidade dos dados
    print(f"\n‚úÖ Valida√ß√£o da Qualidade dos Dados:")
    
    # Consist√™ncia temporal
    if 'timestamp' in df.columns:
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        time_gaps = df['timestamp'].diff()
        large_gaps = time_gaps[time_gaps > pd.Timedelta(seconds=30)]
        
        if len(large_gaps) > 0:
            print(f"  ‚ö†Ô∏è {len(large_gaps)} gaps temporais > 30s detectados")
        else:
            print(f"  ‚úÖ Timeline consistente")
    
    # Balanceamento falha/recupera√ß√£o
    balance_ratio = len(recoveries) / len(failures) if len(failures) > 0 else 0
    if balance_ratio < 0.8:
        print(f"  ‚ö†Ô∏è Baixa taxa de recupera√ß√£o: {balance_ratio:.1%}")
    elif balance_ratio > 1.1:
        print(f"  ‚ö†Ô∏è Mais recupera√ß√µes que falhas: {balance_ratio:.1%}")
    else:
        print(f"  ‚úÖ Balanceamento adequado falhas/recupera√ß√µes: {balance_ratio:.1%}")
    
    # Dados ausentes cr√≠ticos
    critical_missing = 0
    if df['target'].isna().sum() > 0:
        critical_missing += df['target'].isna().sum()
        print(f"  ‚ö†Ô∏è {df['target'].isna().sum()} eventos sem alvo definido")
    
    if df['failure_mode'].isna().sum() > len(df[df['event_type'].isin(['simulation_started', 'simulation_stopped'])]):
        missing_modes = df['failure_mode'].isna().sum() - len(df[df['event_type'].isin(['simulation_started', 'simulation_stopped'])])
        critical_missing += missing_modes
        print(f"  ‚ö†Ô∏è {missing_modes} eventos sem modo de falha")
    
    if critical_missing == 0:
        print(f"  ‚úÖ Todos os campos cr√≠ticos preenchidos")
    
    print(f"\nüéØ Resumo da Valida√ß√£o:")
    
    # Calcular score de qualidade
    quality_score = 100
    
    if len(large_gaps) > 0:
        quality_score -= 10
    
    if balance_ratio < 0.8 or balance_ratio > 1.1:
        quality_score -= 15
    
    if critical_missing > 0:
        quality_score -= 20
    
    if len(outliers) / len(recovery_times) > 0.1:
        quality_score -= 10
    
    if quality_score >= 90:
        status = "üü¢ EXCELENTE"
    elif quality_score >= 75:
        status = "üü° BOM"
    elif quality_score >= 60:
        status = "üü† ACEIT√ÅVEL"
    else:
        status = "üî¥ PROBLEMAS"
    
    print(f"  Score de qualidade: {quality_score}/100 {status}")
    
    # Recomenda√ß√µes
    print(f"\nüí° Recomenda√ß√µes:")
    
    if sim_hours < 100:
        print(f"  ‚Ä¢ Considere simula√ß√µes mais longas (>100h) para estat√≠sticas mais robustas")
    
    if len(failures) < 50:
        print(f"  ‚Ä¢ Aumente a taxa de falhas para obter mais amostras")
    
    if recovery_times.std() > recovery_times.mean():
        print(f"  ‚Ä¢ Alta variabilidade nos tempos de recupera√ß√£o - investigar causas")
    
    if acceleration < 1000:
        print(f"  ‚Ä¢ Considere maior acelera√ß√£o para simula√ß√µes mais eficientes")
    
    print(f"  ‚Ä¢ CSV validado e pronto para an√°lise acad√™mica ‚úÖ")
    
    return {
        'total_events': len(df),
        'failures': len(failures),
        'recoveries': len(recoveries),
        'quality_score': quality_score,
        'simulated_hours': sim_hours,
        'real_minutes': real_minutes,
        'acceleration': acceleration
    }

if __name__ == "__main__":
    import sys
    if len(sys.argv) != 2:
        print("Uso: python3 analyze_csv.py <arquivo.csv>")
        sys.exit(1)
    
    csv_file = sys.argv[1]
    result = analyze_reliability_csv(csv_file)
    print(f"\nüìä An√°lise conclu√≠da: {result}")